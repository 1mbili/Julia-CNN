{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93afd9f6",
   "metadata": {},
   "source": [
    "### Structures\n",
    "Definition of basic structures for computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1b8ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets, Flux, Statistics\n",
    "train_data = MLDatasets.MNIST(split=:train)\n",
    "test_data  = MLDatasets.MNIST(split=:test)\n",
    "\n",
    "\n",
    "function loader(data)\n",
    "    dim1, dim2, dim3 = size(data.features)\n",
    "    x = reshape(data.features, dim1 * dim2, dim3)\n",
    "    y = data.targets\n",
    "    #x4dim = reshape(data.features, 28, 28, 1, :) # insert trivial channel dim\n",
    "    yhot  = Flux.onehotbatch(data.targets, 0:9)  # make a 10×60000 OneHotMatrix\n",
    "    return x, y, yhot\n",
    "    #Flux.DataLoader((x4dim, yhot); batchsize, shuffle=true)\n",
    "end\n",
    "\n",
    "x1, y1, yhot = loader(train_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f929c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 13 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstract type GraphNode end\n",
    "abstract type Operator <: GraphNode end\n",
    "\n",
    "struct Constant{T} <: GraphNode\n",
    "    output :: T\n",
    "end\n",
    "\n",
    "mutable struct Variable <: GraphNode\n",
    "    output :: Any\n",
    "    gradient :: Any\n",
    "    name :: String\n",
    "    Variable(output; name=\"?\") = new(output, nothing, name)\n",
    "end\n",
    "\n",
    "mutable struct ScalarOperator{F} <: Operator\n",
    "    inputs :: Any\n",
    "    output :: Any\n",
    "    gradient :: Any\n",
    "    name :: String\n",
    "    ScalarOperator(fun, inputs...; name=\"?\") = new{typeof(fun)}(inputs, nothing, nothing, name)\n",
    "end\n",
    "\n",
    "mutable struct BroadcastedOperator{F} <: Operator\n",
    "    inputs :: Any\n",
    "    output :: Any\n",
    "    gradient :: Any\n",
    "    name :: String\n",
    "    BroadcastedOperator(fun, inputs...; name=\"?\") = new{typeof(fun)}(inputs, nothing, nothing, name)\n",
    "end\n",
    "import Base: show, summary\n",
    "show(io::IO, x::ScalarOperator{F}) where {F} = print(io, \"op \", x.name, \"(\", F, \")\");\n",
    "show(io::IO, x::BroadcastedOperator{F}) where {F} = print(io, \"op.\", x.name, \"(\", F, \")\", x.inputs, x.output, x.gradient);\n",
    "show(io::IO, x::Constant) = print(io, \"const \", x.output)\n",
    "show(io::IO, x::Variable) = begin\n",
    "    print(io, \"var \", x.name);\n",
    "    print(io, \"\\n ┣━ ^ \"); summary(io, x.output)\n",
    "    print(io, \"\\n ┗━ ∇ \");  summary(io, x.gradient)\n",
    "end\n",
    "function visit(node::GraphNode, visited, order)\n",
    "    if node ∈ visited\n",
    "    else\n",
    "        push!(visited, node)\n",
    "        push!(order, node)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "    \n",
    "function visit(node::Operator, visited, order)\n",
    "    if node ∈ visited\n",
    "    else\n",
    "        push!(visited, node)\n",
    "        for input in node.inputs\n",
    "            visit(input, visited, order)\n",
    "        end\n",
    "        push!(order, node)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function topological_sort(head::GraphNode)\n",
    "    visited = Set()\n",
    "    order = Vector()\n",
    "    visit(head, visited, order)\n",
    "    return order\n",
    "end\n",
    "reset!(node::Constant) = nothing\n",
    "reset!(node::Variable) = node.gradient = nothing\n",
    "reset!(node::Operator) = node.gradient = nothing\n",
    "\n",
    "compute!(node::Constant) = nothing\n",
    "compute!(node::Variable) = nothing\n",
    "compute!(node::Operator) =\n",
    "    node.output = forward(node, [input.output for input in node.inputs]...)\n",
    "\n",
    "function forward!(order::Vector)\n",
    "    for node in order\n",
    "        compute!(node)\n",
    "        reset!(node)\n",
    "    end\n",
    "    return last(order).output\n",
    "end\n",
    "update!(node::Constant, gradient) = nothing\n",
    "update!(node::GraphNode, gradient) = if isnothing(node.gradient)\n",
    "    node.gradient = gradient else node.gradient .+= gradient\n",
    "end\n",
    "\n",
    "function backward!(order::Vector; seed=1.0)\n",
    "    result = last(order)\n",
    "    result.gradient = seed\n",
    "    @assert length(result.output) == 1 \"Gradient is defined only for scalar functions\"\n",
    "    for node in reverse(order)\n",
    "        backward!(node)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function backward!(node::Constant) end\n",
    "function backward!(node::Variable) end\n",
    "function backward!(node::Operator)\n",
    "    inputs = node.inputs\n",
    "    gradients = backward(node, [input.output for input in inputs]..., node.gradient)\n",
    "    for (input, gradient) in zip(inputs, gradients)\n",
    "        update!(input, gradient)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "import Base: ^\n",
    "^(x::GraphNode, n::GraphNode) = ScalarOperator(^, x, n)\n",
    "forward(::ScalarOperator{typeof(^)}, x, n) = return x^n\n",
    "backward(::ScalarOperator{typeof(^)}, x, n, g) = tuple(g * n * x ^ (n-1), g * log(abs(x)) * x ^ n)\n",
    "import Base: sin\n",
    "sin(x::GraphNode) = ScalarOperator(sin, x)\n",
    "forward(::ScalarOperator{typeof(sin)}, x) = return sin(x)\n",
    "backward(::ScalarOperator{typeof(sin)}, x, g) = tuple(g * cos(x))\n",
    "import Base: exp\n",
    "exp(x::GraphNode) = ScalarOperator(exp, x)\n",
    "forward(::ScalarOperator{typeof(exp)}, x) = return exp(x)\n",
    "backward(::ScalarOperator{typeof(exp)}, x, g) = tuple(g * exp(x))\n",
    "\n",
    "\n",
    "import Base: *\n",
    "import LinearAlgebra: mul!\n",
    "# x * y (aka matrix multiplication)\n",
    "*(A::GraphNode, x::GraphNode) = BroadcastedOperator(mul!, A, x)\n",
    "forward(::BroadcastedOperator{typeof(mul!)}, A, x) = return A * x\n",
    "backward(::BroadcastedOperator{typeof(mul!)}, A, x, g) = tuple(g * x', A' * g)\n",
    "\n",
    "# x .* y (element-wise multiplication)pu\n",
    "Base.Broadcast.broadcasted(*, x::GraphNode, y::GraphNode) = BroadcastedOperator(*, x, y)\n",
    "forward(::BroadcastedOperator{typeof(*)}, x, y) = return x .* y\n",
    "backward(node::BroadcastedOperator{typeof(*)}, x, y, g) = let\n",
    "    ones_vec = ones(length(node.output)) # I wektor jednostkowy\n",
    "    Jx = diagm(y .* ones_vec) # I(length(node.output)) * yI\n",
    "    Jy = diagm(x .* ones_vec)\n",
    "    tuple(Jx' * g, Jy' * g)\n",
    "end\n",
    "Base.Broadcast.broadcasted(-, x::GraphNode, y::GraphNode) = BroadcastedOperator(-, x, y)\n",
    "forward(::BroadcastedOperator{typeof(-)}, x, y) = return x .- y\n",
    "backward(::BroadcastedOperator{typeof(-)}, x, y, g) = tuple(g,-g)\n",
    "Base.Broadcast.broadcasted(+, x::GraphNode, y::GraphNode) = BroadcastedOperator(+, x, y)\n",
    "forward(::BroadcastedOperator{typeof(+)}, x, y) = return x .+ y\n",
    "backward(::BroadcastedOperator{typeof(+)}, x, y, g) = tuple(g, g)\n",
    "import Base: sum\n",
    "sum(x::GraphNode) = BroadcastedOperator(sum, x)\n",
    "forward(::BroadcastedOperator{typeof(sum)}, x) = return sum(x)\n",
    "backward(::BroadcastedOperator{typeof(sum)}, x, g) = let\n",
    "    𝟏 = ones(length(x))\n",
    "    J = 𝟏'\n",
    "    tuple(J' * g)\n",
    "end\n",
    "\n",
    "\n",
    "Base.Broadcast.broadcasted(/, x::GraphNode, y::GraphNode) = BroadcastedOperator(/, x, y)\n",
    "forward(::BroadcastedOperator{typeof(/)}, x, y) = return x ./ y\n",
    "backward(node::BroadcastedOperator{typeof(/)}, x, y::Real, g) = let\n",
    "    𝟏 = ones(length(node.output))\n",
    "    Jx = diagm(𝟏 ./ y)\n",
    "    Jy = (-x ./ y .^2)\n",
    "    tuple(Jx' * g, Jy' * g)\n",
    "end\n",
    "\n",
    "import Base: max\n",
    "Base.Broadcast.broadcasted(max, x::GraphNode, y::GraphNode) = BroadcastedOperator(max, x, y)\n",
    "forward(::BroadcastedOperator{typeof(max)}, x, y) = return max.(x, y)\n",
    "backward(::BroadcastedOperator{typeof(max)}, x, y, g) = let\n",
    "    Jx = diagm(isless.(y, x))\n",
    "    Jy = diagm(isless.(x, y))\n",
    "    tuple(Jx' * g, Jy' * g)\n",
    "end\n",
    "\n",
    "import Base: log\n",
    "log(x::GraphNode) = BroadcastedOperator(log, x)\n",
    "forward(::BroadcastedOperator{typeof(log)}, x) = return log.(x)\n",
    "backward(::BroadcastedOperator{typeof(log)}, x, g) = let\n",
    "    J = diagm(1 ./ x)\n",
    "    tuple(J' * g)\n",
    "end\n",
    "\n",
    "\n",
    "σ(x::GraphNode) = BroadcastedOperator(σ, x)\n",
    "forward(::BroadcastedOperator{typeof(σ)}, x) = return 1.0 ./ (1.0 .+ exp.(-x))\n",
    "backward(::BroadcastedOperator{typeof(σ)}, x, g) = let\n",
    "    J = diagm(1.0 ./ (1.0 .+ exp.(-x))).*(1.0 .- (1.0 ./ (1.0 .+ exp.(-x))))\n",
    "    tuple(J' * g)\n",
    "end\n",
    "\n",
    "Base.Broadcast.broadcasted(^, x::GraphNode, y::GraphNode) = BroadcastedOperator(^, x, y)\n",
    "forward(::BroadcastedOperator{typeof(^)}, x, y) = return x .^ y\n",
    "backward(node::BroadcastedOperator{typeof(^)}, x, y, g) = let\n",
    "    Jx = diagm(y .* x .^ (y .- 1.0))\n",
    "    Jy = diagm(log.(abs.(x)) .* x .^ y)\n",
    "    tuple(Jx' * g, Jy' * g)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6de282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 14 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_cross_entropy(y_predicted::GraphNode, y::GraphNode) = BroadcastedOperator(logit_cross_entropy, y_predicted, y)\n",
    "forward(::BroadcastedOperator{typeof(logit_cross_entropy)}, y_predicted, y) =\n",
    "    let\n",
    "        y_predicted = y_predicted .- maximum(y_predicted)\n",
    "        y_predicted = exp.(y_predicted) ./ sum(exp.(y_predicted))\n",
    "        loss = sum(log.(y_predicted) .* y) * -1.0\n",
    "        return loss\n",
    "    end\n",
    "backward(::BroadcastedOperator{typeof(logit_cross_entropy)}, y_predicted, y, g) =\n",
    "    let\n",
    "        y_predicted = y_predicted .- maximum(y_predicted)\n",
    "        y_predicted = exp.(y_predicted) ./ sum(exp.(y_predicted))\n",
    "        return tuple(g .* (y_predicted - y))\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b607dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Variable([1.9514772580227577, 1.848623792879922, -6.456514365666464, -5.10149420660439, 3.5482988599977925, -2.210665982825723, 4.338133361390976, -8.256227686203022, -9.262014936475973, -1.3432975629321589], name=\"x1\")\n",
    "x2 = Variable([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], name=\"x2\")\n",
    "\n",
    "b = logit_cross_entropy(x1, x2)\n",
    "\n",
    "order = topological_sort(b)\n",
    "currentloss = forward!(order)\n",
    "backward!(order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daddb30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0b11f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "order[3].gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "947167f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13235175009777303"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sin(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9df85647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit_cross_entropy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function log_softmax(x)\n",
    "    # Subtract the max value for numerical stability\n",
    "    shift_x = x .- maximum(x)\n",
    "    log_exp_sum = log.(sum(exp.(shift_x)))\n",
    "    return shift_x .- log_exp_sum\n",
    "end\n",
    "\n",
    "\n",
    "function logit_cross_entropy(ŷ::GraphNode, y::GraphNode)\n",
    "    return .-sum(y .* log(ŷ) .+ (1 .- y) .* log(1 .- ŷ))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0803d",
   "metadata": {},
   "source": [
    "### The simplest multilayer-perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b0d7acd",
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching log(::BroadcastedOperator{typeof(mul!)})\n\nClosest candidates are:\n  log(!Matched::Float64)\n   @ Base special\\log.jl:267\n  log(!Matched::BigFloat)\n   @ Base mpfr.jl:727\n  log(!Matched::Missing, !Matched::Missing)\n   @ Base math.jl:1584\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching log(::BroadcastedOperator{typeof(mul!)})\n",
      "\n",
      "Closest candidates are:\n",
      "  log(!Matched::Float64)\n",
      "   @ Base special\\log.jl:267\n",
      "  log(!Matched::BigFloat)\n",
      "   @ Base mpfr.jl:727\n",
      "  log(!Matched::Missing, !Matched::Missing)\n",
      "   @ Base math.jl:1584\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] logit_cross_entropy(ŷ::BroadcastedOperator{typeof(mul!)}, y::Variable)\n",
      "   @ Main d:\\Studia\\Chabrystyka\\W04 (1).ipynb:10\n",
      " [2] net(x::Variable, wh::Variable, wo::Variable, y::Variable)\n",
      "   @ Main d:\\Studia\\Chabrystyka\\W04 (1).ipynb:24\n",
      " [3] top-level scope\n",
      "   @ d:\\Studia\\Chabrystyka\\W04 (1).ipynb:28"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "Wh  = Variable(randn(10,784), name=\"wh\")\n",
    "Wo  = Variable(randn(2,10), name=\"wo\")\n",
    "x = Variable(x1[:, 1], name=\"x\")\n",
    "#y = Variable(yhot[:,1], name=\"y\")\n",
    "#x = Variable([1.98, 4.434], name=\"x\")\n",
    "y = Variable([0.064, 0.1234], name=\"y\")\n",
    "\n",
    "losses = Float64[]\n",
    "\n",
    "function dense(w, b, x, activation) return activation(w * x .+ b) end\n",
    "function dense(w, x, activation) return activation(w * x) end\n",
    "function dense(w, x) return w * x end\n",
    "\n",
    "function mean_squared_loss(y, ŷ)\n",
    "    return sum(Constant(0.5) .* (y .- ŷ) .^ Constant(2))\n",
    "end\n",
    "\n",
    "function net(x, wh, wo, y)\n",
    "    x̂ = dense(wh, x, σ)\n",
    "    x̂.name = \"x̂\"\n",
    "    ŷ = dense(wo, x̂)\n",
    "    ŷ.name = \"ŷ\"\n",
    "    E = logit_cross_entropy(ŷ, y)\n",
    "    E.name = \"loss\"\n",
    "    return topological_sort(E)\n",
    "end\n",
    "graph = net(x, Wh, Wo, y)\n",
    "forward!(graph)\n",
    "backward!(graph)\n",
    "\n",
    "for (i,n) in enumerate(graph)\n",
    "    print(i, \". \"); println(n)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c457220",
   "metadata": {},
   "source": [
    "### Manual derivatives for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54e7cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: [2.6569395463993826]\n",
      "Current loss: [2.2946906133559444]\n",
      "Current loss: [1.9682890420032868]\n",
      "Current loss: [1.6770251382036299]\n",
      "Current loss: [1.4201807795922223]\n",
      "Current loss: [1.1966209745623364]\n",
      "Current loss: [1.00452876090821]\n",
      "Current loss: [0.8413701620291453]\n",
      "Current loss: [0.7040700678099885]\n",
      "Current loss: [0.5892978041825421]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i=1:10\n",
    "    currentloss = forward!(graph)\n",
    "    backward!(graph)\n",
    "    Wh.output -= 0.01Wh.gradient\n",
    "    Wo.output -= 0.01Wo.gradient\n",
    "    println(\"Current loss: \", currentloss)\n",
    "    push!(losses, first(currentloss))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "romance-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 8.862781216261547\n",
       " 8.015221933977145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa7a9849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Installing matplotlib via the Conda matplotlib package...\n",
      "└ @ PyCall C:\\Users\\mbili\\.julia\\packages\\PyCall\\1gn3u\\src\\PyCall.jl:719\n",
      "┌ Info: Running `conda install -y matplotlib` in root environment\n",
      "└ @ Conda C:\\Users\\mbili\\.julia\\packages\\Conda\\sDjAP\\src\\Conda.jl:181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 23.11.0\n",
      "    latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\mbili\\.julia\\conda\\3\\x86_64\n",
      "\n",
      "  added / updated specs:\n",
      "    - matplotlib\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2024.3.11  |       haa95532_0         128 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         128 KB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2023.12.12-haa95532_0 --> 2024.3.11-haa95532_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "ename": "InitError",
     "evalue": "InitError: PyError (PyImport_ImportModule\n\nThe Python package matplotlib could not be imported by pyimport. Usually this means\nthat you did not install matplotlib in the Python version being used by PyCall.\n\nPyCall is currently configured to use the Julia-specific Python distribution\ninstalled by the Conda.jl package.  To install the matplotlib module, you can\nuse `pyimport_conda(\"matplotlib\", PKG)`, where PKG is the Anaconda\npackage that contains the module matplotlib, or alternatively you can use the\nConda package directly (via `using Conda` followed by `Conda.add` etcetera).\n\nAlternatively, if you want to use a different Python distribution on your\nsystem, such as a system-wide Python (as opposed to the Julia-specific Python),\nyou can re-configure PyCall with that Python.   As explained in the PyCall\ndocumentation, set ENV[\"PYTHON\"] to the path/name of the python executable\nyou want to use, run Pkg.build(\"PyCall\"), and re-launch Julia.\n\n) <class 'ImportError'>\nImportError('DLL load failed while importing _imaging: Nie można odnaleźć określonego modułu.')\n  File \"C:\\Users\\mbili\\.julia\\conda\\3\\x86_64\\lib\\site-packages\\matplotlib\\__init__.py\", line 161, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"C:\\Users\\mbili\\.julia\\conda\\3\\x86_64\\lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"C:\\Users\\mbili\\.julia\\conda\\3\\x86_64\\lib\\site-packages\\matplotlib\\colors.py\", line 52, in <module>\n    from PIL import Image\n  File \"C:\\Users\\mbili\\.julia\\conda\\3\\x86_64\\lib\\site-packages\\PIL\\Image.py\", line 84, in <module>\n    from . import _imaging as core\n\nduring initialization of module PyPlot",
     "output_type": "error",
     "traceback": [
      "InitError: PyError (PyImport_ImportModule\n",
      "\n",
      "The Python package matplotlib could not be imported by pyimport. Usually this means\n",
      "that you did not install matplotlib in the Python version being used by PyCall.\n",
      "\n",
      "PyCall is currently configured to use the Julia-specific Python distribution\n",
      "installed by the Conda.jl package.  To install the matplotlib module, you can\n",
      "use `pyimport_conda(\"matplotlib\", PKG)`, where PKG is the Anaconda\n",
      "package that contains the module matplotlib, or alternatively you can use the\n",
      "Conda package directly (via `using Conda` followed by `Conda.add` etcetera).\n",
      "\n",
      "Alternatively, if you want to use a different Python distribution on your\n",
      "system, such as a system-wide Python (as opposed to the Julia-specific Python),\n",
      "you can re-configure PyCall with that Python.   As explained in the PyCall\n",
      "documentation, set ENV[\"PYTHON\"] to the path/name of the python executable\n",
      "you want to use, run Pkg.build(\"PyCall\"), and re-launch Julia.\n",
      "\n",
      ") <class 'ImportError'>\n",
      "ImportError('DLL load failed while importing _imaging: Nie można odnaleźć określonego modułu.')\n",
      "  File \"C:\\Users\\mbili\\.julia\\conda\\3\\x86_64\\lib\\site-packages\\matplotlib\\__init__.py\", line 161, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\mbili\\.julia\\conda\\3\\x86_64\\lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\mbili\\.julia\\conda\\3\\x86_64\\lib\\site-packages\\matplotlib\\colors.py\", line 52, in <module>\n",
      "    from PIL import Image\n",
      "  File \"C:\\Users\\mbili\\.julia\\conda\\3\\x86_64\\lib\\site-packages\\PIL\\Image.py\", line 84, in <module>\n",
      "    from . import _imaging as core\n",
      "\n",
      "during initialization of module PyPlot\n",
      "\n",
      "Stacktrace:\n",
      "  [1] pyimport(name::String)\n",
      "    @ PyCall C:\\Users\\mbili\\.julia\\packages\\PyCall\\1gn3u\\src\\PyCall.jl:558\n",
      "  [2] pyimport_conda(modulename::String, condapkg::String, channel::String)\n",
      "    @ PyCall C:\\Users\\mbili\\.julia\\packages\\PyCall\\1gn3u\\src\\PyCall.jl:722\n",
      "  [3] pyimport_conda\n",
      "    @ C:\\Users\\mbili\\.julia\\packages\\PyCall\\1gn3u\\src\\PyCall.jl:715 [inlined]\n",
      "  [4] __init__()\n",
      "    @ PyPlot C:\\Users\\mbili\\.julia\\packages\\PyPlot\\2MlrT\\src\\init.jl:174\n",
      "  [5] run_module_init(mod::Module, i::Int64)\n",
      "    @ Base .\\loading.jl:1134\n",
      "  [6] register_restored_modules(sv::Core.SimpleVector, pkg::Base.PkgId, path::String)\n",
      "    @ Base .\\loading.jl:1122\n",
      "  [7] _include_from_serialized(pkg::Base.PkgId, path::String, ocachepath::String, depmods::Vector{Any})\n",
      "    @ Base .\\loading.jl:1067\n",
      "  [8] _require_search_from_serialized(pkg::Base.PkgId, sourcepath::String, build_id::UInt128)\n",
      "    @ Base .\\loading.jl:1581\n",
      "  [9] _require(pkg::Base.PkgId, env::String)\n",
      "    @ Base .\\loading.jl:1938\n",
      " [10] __require_prelocked(uuidkey::Base.PkgId, env::String)\n",
      "    @ Base .\\loading.jl:1812\n",
      " [11] #invoke_in_world#3\n",
      "    @ .\\essentials.jl:926 [inlined]\n",
      " [12] invoke_in_world\n",
      "    @ .\\essentials.jl:923 [inlined]\n",
      " [13] _require_prelocked(uuidkey::Base.PkgId, env::String)\n",
      "    @ Base .\\loading.jl:1803\n",
      " [14] macro expansion\n",
      "    @ .\\loading.jl:1790 [inlined]\n",
      " [15] macro expansion\n",
      "    @ .\\lock.jl:267 [inlined]\n",
      " [16] __require(into::Module, mod::Symbol)\n",
      "    @ Base .\\loading.jl:1753\n",
      " [17] #invoke_in_world#3\n",
      "    @ .\\essentials.jl:926 [inlined]\n",
      " [18] invoke_in_world\n",
      "    @ .\\essentials.jl:923 [inlined]\n",
      " [19] require(into::Module, mod::Symbol)\n",
      "    @ Base .\\loading.jl:1746\n",
      " [20] eval\n",
      "    @ .\\boot.jl:385 [inlined]\n",
      " [21] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base .\\loading.jl:2076\n",
      " [22] #invokelatest#2\n",
      "    @ .\\essentials.jl:892 [inlined]\n",
      " [23] invokelatest\n",
      "    @ .\\essentials.jl:889 [inlined]\n",
      " [24] (::VSCodeServer.var\"#214#215\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer c:\\Users\\mbili\\.vscode\\extensions\\julialang.language-julia-1.75.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:19\n",
      " [25] withpath(f::VSCodeServer.var\"#214#215\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer c:\\Users\\mbili\\.vscode\\extensions\\julialang.language-julia-1.75.2\\scripts\\packages\\VSCodeServer\\src\\repl.jl:274\n",
      " [26] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer c:\\Users\\mbili\\.vscode\\extensions\\julialang.language-julia-1.75.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:13\n",
      " [27] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC c:\\Users\\mbili\\.vscode\\extensions\\julialang.language-julia-1.75.2\\scripts\\packages\\JSONRPC\\src\\typed.jl:67\n",
      " [28] serve_notebook(pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; crashreporting_pipename::String)\n",
      "    @ VSCodeServer c:\\Users\\mbili\\.vscode\\extensions\\julialang.language-julia-1.75.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:139\n",
      " [29] top-level scope\n",
      "    @ c:\\Users\\mbili\\.vscode\\extensions\\julialang.language-julia-1.75.2\\scripts\\notebook\\notebook.jl:35"
     ]
    }
   ],
   "source": [
    "using PyPlot\n",
    "semilogy(losses, \".\")\n",
    "xlabel(\"epoch\")\n",
    "ylabel(\"loss\")\n",
    "grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92464b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 12 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "softmax(x::GraphNode) = BroadcastedOperator(softmax, x)\n",
    "forward(::BroadcastedOperator{typeof(softmax)}, x) = return exp.(x) ./ sum(exp.(x))\n",
    "backward(node::BroadcastedOperator{typeof(softmax)}, x, g) = let\n",
    "    y = node.output\n",
    "    J = diagm(y) .- y * y'\n",
    "    tuple(J' * g)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exact-appendix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rosenbrock (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rosenbrock(x, y) = (Constant(1.0) .- x .* x) .+ Constant(100.0) .* (y .- x .* x) .* (y .- x .* x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "burning-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13-element Vector{Any}:\n",
       " const 1.0\n",
       " var x\n",
       " ┣━ ^ 1-element Vector{Float64}\n",
       " ┗━ ∇ Nothing\n",
       " op.?(typeof(*))\n",
       " op.?(typeof(-))\n",
       " const 100.0\n",
       " var y\n",
       " ┣━ ^ 1-element Vector{Float64}\n",
       " ┗━ ∇ Nothing\n",
       " op.?(typeof(*))\n",
       " op.?(typeof(-))\n",
       " op.?(typeof(*))\n",
       " op.?(typeof(*))\n",
       " op.?(typeof(-))\n",
       " op.?(typeof(*))\n",
       " op.?(typeof(+))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = Variable([0.], name=\"x\")\n",
    "y = Variable([0.], name=\"y\")\n",
    "graph = topological_sort(rosenbrock(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "connected-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "v  = -1:.1:+1\n",
    "n  = length(v)\n",
    "z  = zeros(n, n)\n",
    "dz = zeros(n, n, 2)\n",
    "for i=1:n, j=1:n\n",
    "    x.output .= v[i]\n",
    "    y.output .= v[j]\n",
    "    z[i,j] = first(forward!(graph)); backward!(graph)\n",
    "    dz[i,j,1] = first(x.gradient)\n",
    "    dz[i,j,2] = first(y.gradient)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "xv = repeat(v, 1, n)\n",
    "yv = repeat(v',n, 1)\n",
    "contourf(xv, yv, z)\n",
    "quiver(xv, yv, dz[:,:,1], dz[:,:,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
